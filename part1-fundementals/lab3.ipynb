{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a650a62",
   "metadata": {},
   "source": [
    "# Function Calling/Tool Use\n",
    "\n",
    "\n",
    "## Just a quick definition\n",
    "\n",
    "Function calling in the context of Large Language Models (LLMs) refers to the ability of the model to invoke external functions or tools during its response generation. Instead of only generating text, the LLM can recognize when a task requires external data or computation, call a predefined function with the appropriate arguments, and then use the function's output to continue its response.\n",
    "\n",
    "Think of having a super smart robot that you can only speak with. Pretty useless at doing anything aside from talking. Now imagine you have given that robot a hammer and some nails. It can now put up that wall painting that's been waiting forever to be hung :D\n",
    "\n",
    "Except, the way we as AI Engineers give AI tools is by defining python functions and describing that function in detail to the LLM so it knows what tools it has access to, what each tool can do, what are its inputs and expected outputs.\n",
    "\n",
    "Just remember, a *tool* in its simplest form is just a *python function* that you have defined. It can be as simple as a calculator function or something like being able to call external APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057f0cfa",
   "metadata": {},
   "source": [
    "![tool-use](../images/tool-use.png)\n",
    "\n",
    "*Image courtesy of [API Deck](https://www.apideck.com/blog/llm-tool-use-and-function-calling)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa669de",
   "metadata": {},
   "source": [
    "## Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16015c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise Exception(\"API key is missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3d86cc",
   "metadata": {},
   "source": [
    "## Step 2: Define a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3997d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfddda44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather(24.343627, 54.497922)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4b3e24",
   "metadata": {},
   "source": [
    "## Step 3: Call a chat model normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23326ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm unable to provide real-time weather data. Please check a reliable weather website or app for the current temperature in Abu Dhabi.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.Client()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the weather like in Abu Dhabi today? Reply only with the temperature in Celsius.\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb899262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'resp_689305953c4881a3ae7bc3ee7e30b8a70f220f510136efac',\n",
       " 'created_at': 1754465685.0,\n",
       " 'error': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'object': 'response',\n",
       " 'output': [ResponseOutputMessage(id='msg_68930595850c81a38055dfe45b18ec8d0f220f510136efac', content=[ResponseOutputText(annotations=[], text=\"I'm unable to provide real-time weather data. Please check a reliable weather website or app for the current temperature in Abu Dhabi.\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message')],\n",
       " 'parallel_tool_calls': True,\n",
       " 'temperature': 1.0,\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [],\n",
       " 'top_p': 1.0,\n",
       " 'background': False,\n",
       " 'max_output_tokens': None,\n",
       " 'max_tool_calls': None,\n",
       " 'previous_response_id': None,\n",
       " 'prompt': None,\n",
       " 'prompt_cache_key': None,\n",
       " 'reasoning': Reasoning(effort=None, generate_summary=None, summary=None),\n",
       " 'safety_identifier': None,\n",
       " 'service_tier': 'default',\n",
       " 'status': 'completed',\n",
       " 'text': ResponseTextConfig(format=ResponseFormatText(type='text')),\n",
       " 'top_logprobs': 0,\n",
       " 'truncation': 'disabled',\n",
       " 'usage': ResponseUsage(input_tokens=35, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=26, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=61),\n",
       " 'user': None,\n",
       " '_request_id': 'req_2d1cb883391ce7922cc107a98362fb78'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa9bee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_68930595850c81a38055dfe45b18ec8d0f220f510136efac',\n",
       " 'content': [ResponseOutputText(annotations=[], text=\"I'm unable to provide real-time weather data. Please check a reliable weather website or app for the current temperature in Abu Dhabi.\", type='output_text', logprobs=[])],\n",
       " 'role': 'assistant',\n",
       " 'status': 'completed',\n",
       " 'type': 'message'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[0].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ab349",
   "metadata": {},
   "source": [
    "## Step 4: Define the input schema for our tool\n",
    "\n",
    "Lets try giving our `get_weather` function as a tool to our AI.\n",
    "\n",
    "Step 1: Define the tool in a format OpenAI can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ead465",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"latitude\": {\"type\": \"number\"},\n",
    "            \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "        \"required\": [\"latitude\", \"longitude\"],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a9f2e8",
   "metadata": {},
   "source": [
    "## Step 5: Pass the tool schema over to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1403cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_6893051619cc819cadecb589f57901340625d1383c6d24a2', created_at=1754465558.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseFunctionToolCall(arguments='{\"latitude\":24.4539,\"longitude\":54.3872}', call_id='call_BImXqbKiHcowxtu3KfLaaVtB', name='get_weather', type='function_call', id='fc_68930516f414819c97bab8e4bcc2a5a80625d1383c6d24a2', status='completed')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='get_weather', parameters={'type': 'object', 'properties': {'latitude': {'type': 'number'}, 'longitude': {'type': 'number'}}, 'required': ['latitude', 'longitude'], 'additionalProperties': False}, strict=True, type='function', description='Get current temperature for provided coordinates in celsius.')], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=54, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=25, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=79), user=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "input_messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Abu Dhabi today?\"}]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22212547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_request_id': 'req_52be7bd56bdc116bf534ff5a5ce205c3',\n",
      " 'background': False,\n",
      " 'created_at': 1754465558.0,\n",
      " 'error': None,\n",
      " 'id': 'resp_6893051619cc819cadecb589f57901340625d1383c6d24a2',\n",
      " 'incomplete_details': None,\n",
      " 'instructions': None,\n",
      " 'max_output_tokens': None,\n",
      " 'max_tool_calls': None,\n",
      " 'metadata': {},\n",
      " 'model': 'gpt-4o-mini-2024-07-18',\n",
      " 'object': 'response',\n",
      " 'output': [ResponseFunctionToolCall(arguments='{\"latitude\":24.4539,\"longitude\":54.3872}', call_id='call_BImXqbKiHcowxtu3KfLaaVtB', name='get_weather', type='function_call', id='fc_68930516f414819c97bab8e4bcc2a5a80625d1383c6d24a2', status='completed')],\n",
      " 'parallel_tool_calls': True,\n",
      " 'previous_response_id': None,\n",
      " 'prompt': None,\n",
      " 'prompt_cache_key': None,\n",
      " 'reasoning': Reasoning(effort=None, generate_summary=None, summary=None),\n",
      " 'safety_identifier': None,\n",
      " 'service_tier': 'default',\n",
      " 'status': 'completed',\n",
      " 'temperature': 1.0,\n",
      " 'text': ResponseTextConfig(format=ResponseFormatText(type='text')),\n",
      " 'tool_choice': 'auto',\n",
      " 'tools': [FunctionTool(name='get_weather', parameters={'type': 'object', 'properties': {'latitude': {'type': 'number'}, 'longitude': {'type': 'number'}}, 'required': ['latitude', 'longitude'], 'additionalProperties': False}, strict=True, type='function', description='Get current temperature for provided coordinates in celsius.')],\n",
      " 'top_logprobs': 0,\n",
      " 'top_p': 1.0,\n",
      " 'truncation': 'disabled',\n",
      " 'usage': ResponseUsage(input_tokens=54, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=25, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=79),\n",
      " 'user': None}\n"
     ]
    }
   ],
   "source": [
    "print(response.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476bcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arguments': '{\"latitude\":24.4539,\"longitude\":54.3872}',\n",
      " 'call_id': 'call_BImXqbKiHcowxtu3KfLaaVtB',\n",
      " 'id': 'fc_68930516f414819c97bab8e4bcc2a5a80625d1383c6d24a2',\n",
      " 'name': 'get_weather',\n",
      " 'status': 'completed',\n",
      " 'type': 'function_call'}\n"
     ]
    }
   ],
   "source": [
    "print(response.output[0].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fea85f",
   "metadata": {},
   "source": [
    "## Step 6: Format the tool call response from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5268da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "\n",
    "print(\"Tool call: \", tool_call)\n",
    "print(\"Arguments: \", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call.arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ff324",
   "metadata": {},
   "source": [
    "## Step 7: Pass on the tool call arguments to our tool/python function\n",
    "\n",
    "We now need to pass on the arguments received by the model to our python function or tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33adbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_weather(args[\"latitude\"], args[\"longitude\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1829435",
   "metadata": {},
   "source": [
    "## Step 8: Append the response of the tool into the message list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c04033",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_messages.append(tool_call)  # append model's function call message\n",
    "input_messages.append({                               # append result message\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": tool_call.call_id,\n",
    "    \"output\": str(result)\n",
    "})\n",
    "\n",
    "pprint(input_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a76b0c",
   "metadata": {},
   "source": [
    "## Step 9: Pass the message list into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")\n",
    "pprint(response_2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30de53b",
   "metadata": {},
   "source": [
    "# Resources:\n",
    "\n",
    "- [OpenAIs Function Calling Guide](https://platform.openai.com/docs/guides/function-calling?api-mode=responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc4aab",
   "metadata": {},
   "source": [
    "## Your Turn: Build Your Own Custom Tool\n",
    "\n",
    "Now that you've seen how to define a Python function as a tool and connect it to an LLM, it's time to get creative!\n",
    "\n",
    "### Pick your challenge\n",
    "**1. Wikipedia Article SUmmarizer**\n",
    "- Fetch a wikipedia article you are interested in learning about and have an LLM summarize it\n",
    "- [Wikipedia API](https://pypi.org/project/Wikipedia-API/)\n",
    "\n",
    "**2. News Summarizer**\n",
    "- Fetch latest headlines or news by topic.\n",
    "- [NewsAPI](https://newsapi.org)\n",
    "- [CurrentsAPI](https://currentsapi.services/en/docs/)\n",
    "\n",
    "**3. Stock Market Data**\n",
    "- Get real-time stock prices or company info\n",
    "- [Alpha Vantage](https://www.alphavantage.co/)\n",
    "- [yfinance](https://pypi.org/project/yfinance/)\n",
    "\n",
    "**4. Movie Info**\n",
    "- Get movie ratings, cast, plot summaries.\n",
    "- [IMDb](https://imdbapi.dev/)\n",
    "- [OMDb API](https://www.omdbapi.com/)\n",
    "\n",
    "**5. NASA API**\n",
    "- Astronomy facts, country data, etc.\n",
    "- [NASA APIs](https://api.nasa.gov/)\n",
    "\n",
    "**6. Your own custom tool**\n",
    "- Think of a real-world use case where an LLM could benefit from calling a custom function.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Tips**:\n",
    "- Use clear function names and docstrings.\n",
    "- Handle input arguments and outputs carefully.\n",
    "- Print the LLM's tool call and your function's output in a readable way.\n",
    "\n",
    "Be sure to place your submissions in `AI-Engineering-Intermediate/Part1/community-contributions`\n",
    "\n",
    "I'm super excited to see what you come up with :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
